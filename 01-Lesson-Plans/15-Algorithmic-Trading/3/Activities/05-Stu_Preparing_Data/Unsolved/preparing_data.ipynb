{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for a Machine Learning Trading Strategy\n",
    "\n",
    "## Background\n",
    "\n",
    "Before adding the power of machine learning into a trading algorithm, it's crucial to prepare the data that you will use to fit the model.\n",
    "\n",
    "In this activity, you’ll prepare training and testing data for fitting a machine learning-powered trading algorithm.\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Read the provided OHLCV data provided in the CSV file into a Pandas DataFrame.\n",
    "\n",
    "    > **Hint:** Remember to set the `date` columns as the DataFrame index and parse the dates.\n",
    "\n",
    "2. Use the `pct_change` function to add a daily returns values column to the DataFrame. Name this column `actual_returns`.\n",
    "\n",
    "    > **Hint:** Remove NAN values from the DataFrame.\n",
    "\n",
    "3. Generate the features and target set as follows:\n",
    "\n",
    "    * Set a short and long window size of 4 and 100 days, respectively, and add the fast and slow simple moving average columns to the DataFrame.\n",
    "\n",
    "      > **Hint:** Remove NAN values from the DataFrame.\n",
    "\n",
    "    * Create the features set by copying the `sma_fast` and `sma_slow` columns to a new DataFrame called `X`.\n",
    "\n",
    "    * Add a `signal` column to the DataFrame setting its value to zeroes.\n",
    "\n",
    "    * Use the Pandas `loc` function to populate the `signal` column as follows: where the `actual_returns` value is greater than or equal to zero, we set the `signal` value to 1. Where the `actual_returns` value is less than zero, we set the `signal` value to −1.\n",
    "\n",
    "    * Create the target set `y` by copying the values of the `signal` column.\n",
    "\n",
    "4. Split the data into training and testing sets as follows.\n",
    "\n",
    "    * Use the pandas `DateOffset` module to set the beginning and end dates for the training the testing sets.\n",
    "\n",
    "    * Set the `training_begin` date to the minimum date in the DataSet.\n",
    "\n",
    "    * Set the ending period for the training data with an offset of 3 months\n",
    "\n",
    "    * Use the `loc` function to generate the training datasets using the `training_begin` and `training_end` dates as lower and upper limits.\n",
    "\n",
    "    * Create the testing sets using the `loc` function to slice the index starting at the `training_end` value and ending at the last record of the datasets.\n",
    "\n",
    "5. Use the `StandardScaler` to standardize the training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the CSV file into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-19 09:30:00</th>\n",
       "      <td>16.90</td>\n",
       "      <td>17.18</td>\n",
       "      <td>16.90</td>\n",
       "      <td>17.095</td>\n",
       "      <td>11522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 09:45:00</th>\n",
       "      <td>17.11</td>\n",
       "      <td>17.44</td>\n",
       "      <td>17.11</td>\n",
       "      <td>17.400</td>\n",
       "      <td>70593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 10:00:00</th>\n",
       "      <td>17.40</td>\n",
       "      <td>17.40</td>\n",
       "      <td>17.25</td>\n",
       "      <td>17.280</td>\n",
       "      <td>38885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 10:15:00</th>\n",
       "      <td>17.27</td>\n",
       "      <td>17.27</td>\n",
       "      <td>17.18</td>\n",
       "      <td>17.200</td>\n",
       "      <td>37046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-19 10:30:00</th>\n",
       "      <td>17.21</td>\n",
       "      <td>17.37</td>\n",
       "      <td>17.19</td>\n",
       "      <td>17.200</td>\n",
       "      <td>46874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      open   high    low   close  volume\n",
       "date                                                    \n",
       "2018-10-19 09:30:00  16.90  17.18  16.90  17.095   11522\n",
       "2018-10-19 09:45:00  17.11  17.44  17.11  17.400   70593\n",
       "2018-10-19 10:00:00  17.40  17.40  17.25  17.280   38885\n",
       "2018-10-19 10:15:00  17.27  17.27  17.18  17.200   37046\n",
       "2018-10-19 10:30:00  17.21  17.37  17.19  17.200   46874"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the OHLCV dataset into a Pandas Dataframe\n",
    "trading_df = pd.read_csv(Path(\"..\\Resources\\ohlcv.csv\"),\n",
    "index_col=\"date\", \n",
    "    infer_datetime_format=True, \n",
    "    parse_dates=True\n",
    ")\n",
    "# Review the DataFrame\n",
    "trading_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a Daily Return Values Column to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_86516/1512038981.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Review the DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrading_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m#display(trading_df.tail())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "# Calculate the daily returns using the closing prices and the pct_change function\n",
    "#trading_df[\"actual_returns\"] = trading_df[\"close\"].pct_change()\n",
    "\n",
    "# Drop all NaN values from the DataFrame\n",
    "#trading_df = trading_df.dropna\n",
    "\n",
    "# Review the DataFrame\n",
    "trading_df.head()\n",
    "#display(trading_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Features and Target Sets\n",
    "\n",
    "### Add the Fast and Slow Simple Moving Average Columns to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_86516/1747374975.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Jamel\\AppData\\Local\\Temp/ipykernel_86516/1747374975.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    trading_df['sma_fast'] = # YOUR CODE HERE!\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Define a window size of 4\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Create a simple moving average (SMA) using the short_window and assign this to a new columns called sma_fast\n",
    "trading_df['sma_fast'] = # YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a window size of 100\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Create a simple moving average (SMA) using the long_window and assign this to a new columns called sma_slow\n",
    "trading_df['sma_slow'] = # YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaNs using dropna()\n",
    "trading_df = # YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the features set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a copy of the sma_fast and sma_slow columns to a new DataFrame called X\n",
    "X = # YOUR CODE HERE!\n",
    "\n",
    "# Display sample data\n",
    "display(X.head())\n",
    "display(X.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column in the trading_df called signal setting its value to zero.\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the signal to buy\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the signal to sell\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the new signal column to a new Series called y.\n",
    "y = # YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data Into Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Training Begin and End Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the start of the training period\n",
    "training_begin = # YOUR CODE HERE!\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the ending period for the training data with an offset of 3 months\n",
    "training_end = # YOUR CODE HERE!\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Training Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = # YOUR CODE HERE!\n",
    "y_train = # YOUR CODE HERE!\n",
    "\n",
    "# Display sample data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = # YOUR CODE HERE!\n",
    "y_test = # YOUR CODE HERE!\n",
    "\n",
    "# Display sample data\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    " \n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = # YOUR CODE HERE!\n",
    " \n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = # YOUR CODE HERE!\n",
    "X_test_scaled = # YOUR CODE HERE!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "88faf968d59841e7ef8a87304018a28eabc64e8d2716b3df8adebfd562b96072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

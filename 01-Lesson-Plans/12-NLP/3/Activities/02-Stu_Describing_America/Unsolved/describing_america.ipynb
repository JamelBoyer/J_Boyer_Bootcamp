{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing America\n",
    "\n",
    "Somehow, the speech delivered by country leaders when they start duties on their charge could shape the line they will follow during their term. In this activity, you will use NLTK and spaCy to analyze the inaugural addresses delivered by the Presidents from the United States since 1798.\n",
    "\n",
    "You will use [the inaugural address corpus](https://www.nltk.org/book/ch02.html#inaugural-address-corpus) from the NLTK library to identify what were the most common adjectives used by U.S. Presidents and how these adjectives describe America."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial considerations\n",
    "\n",
    "In the `Initial imports` cell, we are importing two modules that are worth highlighting.\n",
    "\n",
    "* The `Counter` module from the `collections` library will allow you to track how many times equivalent values are found in a list.\n",
    "\n",
    "* The `inaugural` module from the `nltk.corpus` library provides some methods to extract information from [the inaugural address corpus](https://www.nltk.org/book/ch02.html#inaugural-address-corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import inaugural\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\Jamel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK's inaugural corpus\n",
    "nltk.download(\"inaugural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model for spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieve the documents IDs and text of the U.S. presidential inaugural addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the IDs of inaugural addresses\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Retrieve the text of inaugural addresses\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Display sample inaugural address\n",
    "print(ids[0])\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Retrieve the most frequent adjective from each inaugural address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def most_freq_adj(text):\n",
    "    \"\"\"\n",
    "    This function used spaCy to get the most common adjective from each text.\n",
    "    \n",
    "    Args:\n",
    "        text (string): The text to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        most_common_adj (list): A list containing a tuple with the most common adjective and its occurrence in the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenizes text and parse each token\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Creates a list with all the adjectives in the text\n",
    "    adjs = [token.text.lower() for token in doc if token.pos_ == 'ADJ']\n",
    "    \n",
    "    # Retrieves the most frequent adjective in the `adjs` list using the Counter module\n",
    "    most_common_adj = Counter(adjs).most_common(1)\n",
    "    \n",
    "    return most_common_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the most common adjective for each inaugural address\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Display sample data\n",
    "print(adjs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame `df_adjs` with the most common adjective for each inaugural address.\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Display sample data from the first ten inaugural addresses\n",
    "df_adjs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyze adjectives over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def all_adj(text):\n",
    "    \"\"\"\n",
    "    This function retrieves all the adjectives on the given text.\n",
    "    \n",
    "    Args:\n",
    "        text (string): The text to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        adjs (list): A list with all the adjectives in the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the text and parse each token\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Create a list with all the adjectives in the text\n",
    "    adjs = [token.text.lower() for token in doc if token.pos_ == 'ADJ']\n",
    "    \n",
    "    return adjs\n",
    "\n",
    "# Import the word_tokenize module from NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_word_counts(text, word):\n",
    "    \"\"\"\n",
    "    This function counts the occurrences of a word in a text.\n",
    "    \n",
    "    Args:\n",
    "        text (string): The text where word counts will be analyzed.\n",
    "        word (string): The word to look into the text.\n",
    "        \n",
    "    Returns:\n",
    "        word_count (int): The counts of the word in the given text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the word_tokenize module from NLTK to tokenize the text\n",
    "    tok = word_tokenize(text)\n",
    "    \n",
    "    # Create a list with all the tokens retrieved from the text\n",
    "    tok = [word.lower() for word in tok]\n",
    "    \n",
    "    # Count the occurrences of the word in the text\n",
    "    word_count = tok.count(word)\n",
    "    \n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `all_adj()` function to create a Python list `all_adjectives` containing all the adjectives from all the inaugural addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store all the adjectives\n",
    "all_adjectives = []\n",
    "\n",
    "# Use a for-loop to retrieve all the adjectives on each inaugural address and concatenate the adjectives fetched to `all_adjectives`\n",
    "# YOUR CODE HERE!\n",
    "    \n",
    "# Print sample data\n",
    "print(all_adjectives[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `most_common()` function from the `Counter` module to fetch the three most frequent adjectives used in the U.S. Presidential inaugural address. The `most_common()` function returns a Python list that you should store in a variable called `most_freq_adjectives`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the three most frequent adjectives\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Print the three most frequent adjectives\n",
    "print(most_freq_adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `get_word_counts()` function to compute the counts of each of the three most frequent adjectives in the U.S. Presidential inaugural addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use list comprehensions to create a list with the counts of each top adjective in the inaugural addresses\n",
    "great_counts = # YOUR CODE HERE!\n",
    "other_counts = # YOUR CODE HERE!\n",
    "own_counts = # YOUR CODE HERE!\n",
    "\n",
    "# Display sample data\n",
    "print(f\"Great counts sample data: {great_counts[:5]}\")\n",
    "print(f\"Other counts sample data: {other_counts[:5]}\")\n",
    "print(f\"Own counts sample data: {own_counts[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Python list `dates` to store the year when every inaugural address was delivered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list `dates` with the year for each inaugural address using the file IDs\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Print sample data\n",
    "print(dates[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Python list `presidents` to store the last name of each U.S. President whose inaugural address is in the `inaugural` corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list `presidents` with the last name of each president\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Print sample data\n",
    "print(presidents[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a DataFrame `df_adjectives` with the Presidents last names and the adjectives counts as columns, and set the `dates` list as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DataFrame data\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Create the DataFrame\n",
    "# YOUR CODE HERE!\n",
    "\n",
    "# Display same data\n",
    "df_adjectives.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a line plot using the `df_adjectives` DataFrame to visualize the usage of the most common adjective over time in the U.S. presidential inaugural addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `df_adjectives` DataFrame to plot frequencies of each adjective over time\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Adjectives describing America"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use spaCy to create a function `describe_america()` that returns the adjectives in all the inaugural addresses that describe the word `America`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_america(text):\n",
    "    \"\"\"\n",
    "    This function retrieves the adjectives in the text that describe the word 'America'.\n",
    "    \n",
    "    Args:\n",
    "        text (string): The text to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        adjs (list): A list of the adjectives that describe the word 'America' in the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the spaCy English language model to tokenize the text and parse each token\n",
    "    # YOUR CODE HERE!\n",
    "\n",
    "    # Create a list with all the adjectives in the text that describe the word 'America'\n",
    "    # YOUR CODE HERE!\n",
    "    \n",
    "    return adjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `describe_america()` function you defined to create a Python list containing all the adjectives describing the word `America` from all the inaugural addresses in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the adjectives\n",
    "america_adjectives = []\n",
    "\n",
    "# Use a for-loop to retrieve all the adjectives that describe the word 'America' on each inaugural address and concatenate the adjectives fetched to `america_adjectives`\n",
    "# YOUR CODE HERE!\n",
    "    \n",
    "# Print the list of the adjectives describing the word 'America'\n",
    "# YOUR CODE HERE!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88faf968d59841e7ef8a87304018a28eabc64e8d2716b3df8adebfd562b96072"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
